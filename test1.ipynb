{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-30T19:38:49.662447700Z",
     "start_time": "2024-09-30T19:38:37.263375100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Jet Brains\\DataSpell\\Attendance using facial rec\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "from retinaface import RetinaFace\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "img_path = \"Ankit Kumar.jpg\"\n",
    "img = cv2.imread(img_path)\n",
    "obj = RetinaFace.detect_faces(img_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T19:39:03.409129900Z",
     "start_time": "2024-09-30T19:38:49.664001100Z"
    }
   },
   "id": "e4f8c184bd395e90",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9995902180671692, 'facial_area': [369, 338, 947, 1067], 'landmarks': {'right_eye': [511.90213, 621.2869], 'left_eye': [783.48425, 608.43036], 'nose': [638.28485, 744.85785], 'mouth_right': [533.3406, 883.25055], 'mouth_left': [762.4401, 871.33966]}}\n"
     ]
    }
   ],
   "source": [
    "for key in obj.keys():\n",
    "    identify = obj[key]\n",
    "    print(identify)\n",
    "    facial_area = identify[\"facial_area\"]\n",
    "    cv2.rectangle(img,(facial_area[0],facial_area[1]),(facial_area[2],facial_area[3]),(255,255,0),3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T19:39:03.483028800Z",
     "start_time": "2024-09-30T19:39:03.408416200Z"
    }
   },
   "id": "92c8fc9eb6376aed",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from deepface import DeepFace"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T19:39:03.694074100Z",
     "start_time": "2024-09-30T19:39:03.424501900Z"
    }
   },
   "id": "b89346f54a292382",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-10-01 01:09:03 - Searching img1.jpg in 11 length datastore\n",
      "24-10-01 01:09:16 - find function duration 12.314710855484009 seconds\n"
     ]
    }
   ],
   "source": [
    "obj_df = DeepFace.find(\"img1.jpg\", \"students\" ,model_name=\"ArcFace\",\n",
    "                         detector_backend=\"retinaface\",distance_metric=\"cosine\",enforce_detection= True,align = False)\n",
    "embedding_objs = DeepFace.represent(img_path= \"img1.jpg\",model_name=\"ArcFace\",\n",
    "detector_backend=\"retinaface\",enforce_detection= True,align = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T19:39:25.999763700Z",
     "start_time": "2024-09-30T19:39:03.698988600Z"
    }
   },
   "id": "3ecd31273393eabb",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    students\\Myself.jpg\n",
      "1     students\\Ankit.jpg\n",
      "Name: identity, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(obj_df[0].identity)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T19:14:51.042064700Z",
     "start_time": "2024-09-29T19:14:51.030175700Z"
    }
   },
   "id": "727f268bd0aab56b",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-29T07:32:30.428576100Z"
    }
   },
   "id": "e04e5e65c6c7541b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bf76aeae2b128e17"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "daab0a02fa82898b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7f9218d78e864b20"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e0ea4cfe43e0cd4c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m facial_area \u001B[38;5;241m=\u001B[39m identity[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfacial_area\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m      6\u001B[0m x1, y1, x2, y2 \u001B[38;5;241m=\u001B[39m facial_area\n\u001B[1;32m----> 7\u001B[0m \u001B[43mcv2\u001B[49m\u001B[38;5;241m.\u001B[39mrectangle(img_rgb, (x1, y1), (x2, y2), (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m255\u001B[39m, \u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Extract and draw landmarks\u001B[39;00m\n\u001B[0;32m     10\u001B[0m landmarks \u001B[38;5;241m=\u001B[39m identity[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlandmarks\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "if isinstance(resp, dict):\n",
    "    for key in resp:\n",
    "        identity = resp[key]\n",
    "        # Extract bounding box coordinates\n",
    "        facial_area = identity[\"facial_area\"]\n",
    "        x1, y1, x2, y2 = facial_area\n",
    "        cv2.rectangle(img_rgb, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Extract and draw landmarks\n",
    "        landmarks = identity[\"landmarks\"]\n",
    "        for landmark in landmarks.values():\n",
    "            cv2.circle(img_rgb, (int(landmark[0]), int(landmark[1])), 2, (255, 0, 0), -1)\n",
    "else:\n",
    "    print(\"No faces detected.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T05:25:07.610316300Z",
     "start_time": "2024-09-29T05:25:07.481573800Z"
    }
   },
   "id": "efe45a9525c90de0",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "def prepare_student_database(student_dir):\n",
    "    student_db = {}\n",
    "    for filename in os.listdir(student_dir):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            filepath = os.path.join(student_dir, filename)\n",
    "            name = os.path.splitext(filename)[0]\n",
    "            try:\n",
    "                # Load image using face_recognition\n",
    "                image = face_recognition.load_image_file(filepath)\n",
    "                encodings = face_recognition.face_encodings(image)\n",
    "                if encodings:\n",
    "                    student_db[name] = encodings[0]\n",
    "                    print(f\"Processed {name}'s image.\")\n",
    "                else:\n",
    "                    print(f\"No face found in {filename}, skipping.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "    return student_db\n",
    "\n",
    "def detect_faces_in_classroom(classroom_image_path):\n",
    "    try:\n",
    "        # Detect faces using RetinaFace\n",
    "        detections = RetinaFace.detect_faces(classroom_image_path)\n",
    "        print(f\"Detected {len(detections)} faces in the classroom image.\")\n",
    "        return detections\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing classroom image: {e}\")\n",
    "        return {}\n",
    "\n",
    "def calculate_cosine_distance(emb1, emb2):\n",
    "    emb1 = np.array(emb1)\n",
    "    emb2 = np.array(emb2)\n",
    "    cos_distance = 1 - np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "    return cos_distance\n",
    "\n",
    "def find_closest_match(detected_embedding, student_db):\n",
    "    min_distance = float('inf')\n",
    "    matched_name = \"Unknown\"\n",
    "    for name, embedding in student_db.items():\n",
    "        distance = calculate_cosine_distance(detected_embedding, embedding)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            matched_name = name\n",
    "    return matched_name, min_distance\n",
    "\n",
    "def match_faces(face_encodings, student_db, tolerance=0.6):\n",
    "    attendance = {name: \"Absent\" for name in student_db.keys()}\n",
    "    for encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(list(student_db.values()), encoding, tolerance=tolerance)\n",
    "        face_distances = face_recognition.face_distance(list(student_db.values()), encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = list(student_db.keys())[best_match_index]\n",
    "            attendance[name] = \"Present\"\n",
    "        else:\n",
    "            print(\"Unknown face detected.\")\n",
    "    return attendance\n",
    "\n",
    "def extract_face_embeddings(classroom_image_path, detections):\n",
    "    image = cv2.imread(classroom_image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    face_encodings = []\n",
    "    face_locations = []\n",
    "\n",
    "    for key, detection in detections.items():\n",
    "        facial_area = detection[\"facial_area\"]  # [x1, y1, x2, y2]\n",
    "        x1, y1, x2, y2 = facial_area\n",
    "        face_image = image_rgb[y1:y2, x1:x2]\n",
    "        encodings = face_recognition.face_encodings(face_image)\n",
    "        if encodings:\n",
    "            face_encodings.append(encodings[0])\n",
    "            face_locations.append((y1, x2, y2, x1))  # Convert to (top, right, bottom, left)\n",
    "        else:\n",
    "            print(f\"No encoding found for face {key}.\")\n",
    "    return face_encodings, face_locations, image\n",
    "\n",
    "def annotate_image(image, detections, face_locations, face_names, output_path='annotated_classroom_retinaface.jpg'):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "        # Label the face\n",
    "        cv2.rectangle(image, (left, bottom - 25), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "        cv2.putText(image, name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    # Save the annotated image\n",
    "    cv2.imwrite(output_path, image)\n",
    "    print(f\"Annotated image saved as {output_path}.\")\n",
    "\n",
    "def save_attendance_to_csv(attendance, csv_filename='attendance_retinaface.csv'):\n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    data = []\n",
    "    for name, status in attendance.items():\n",
    "        data.append({\"Name\": name, \"Status\": status, \"Timestamp\": date_time})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Attendance has been recorded in {csv_filename}.\")\n",
    "\n",
    "def main():\n",
    "    student_directory = 'students/'\n",
    "    classroom_image_path = 'classroom.jpg'\n",
    "\n",
    "    # Step 1: Prepare the student database\n",
    "    print(\"Preparing the student database...\")\n",
    "    student_db = prepare_student_database(student_directory)\n",
    "\n",
    "    if not student_db:\n",
    "        print(\"No student encodings found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Detect faces in the classroom image\n",
    "    print(\"Detecting faces in the classroom image...\")\n",
    "    detections = detect_faces_in_classroom(classroom_image_path)\n",
    "\n",
    "    if not detections:\n",
    "        print(\"No faces detected in the classroom image. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Step 3: Extract face encodings\n",
    "    print(\"Extracting face encodings from detected faces...\")\n",
    "    face_encodings, face_locations, image = extract_face_embeddings(classroom_image_path, detections)\n",
    "\n",
    "    if not face_encodings:\n",
    "        print(\"No face encodings extracted. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Step 4: Match detected faces with the student database\n",
    "    print(\"Matching detected faces with the student database...\")\n",
    "    attendance = match_faces(face_encodings, student_db)\n",
    "\n",
    "    # Step 5: Annotate the classroom image\n",
    "    print(\"Annotating the classroom image...\")\n",
    "    face_names = []\n",
    "    for encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(list(student_db.values()), encoding, tolerance=0.6)\n",
    "        face_distances = face_recognition.face_distance(list(student_db.values()), encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = list(student_db.keys())[best_match_index]\n",
    "            face_names.append(name)\n",
    "        else:\n",
    "            face_names.append(\"Unknown\")\n",
    "\n",
    "    annotate_image(image, detections, face_locations, face_names, output_path='annotated_classroom_retinaface.jpg')\n",
    "\n",
    "    # Step 6: Save attendance to CSV\n",
    "    print(\"Saving attendance to CSV...\")\n",
    "    save_attendance_to_csv(attendance, csv_filename='attendance_retinaface.csv')\n",
    "\n",
    "    # Optional: Display attendance\n",
    "    print(\"\\nAttendance Report:\")\n",
    "    for name, status in attendance.items():\n",
    "        print(f\"{name}: {status}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-29T05:25:07.610316300Z"
    }
   },
   "id": "cc768e506bc42e17"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
