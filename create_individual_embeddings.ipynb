{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing the important libraries \n",
    "\n",
    "retinaface is used to detect where the face is present in the entire face and \n",
    "deep face is used to create the  embeddings \n",
    "cv2 is used to read the image from the file\n",
    "os is used to navigate the directories and fetch the files\n",
    "numpy is used to manipulate the necessary data structures"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b23f10276050236"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-11T06:29:55.645806600Z",
     "start_time": "2024-12-11T06:29:44.035731900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Jet Brains\\DataSpell\\Attendance using facial rec\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "from retinaface import RetinaFace\n",
    "from deepface import DeepFace\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import datetime as datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "FAISS is FaceBook AI similarity search and "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c069fc5be7ef6e01"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import faiss\n",
    "from datetime import datetime\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T06:29:56.025098200Z",
     "start_time": "2024-12-11T06:29:55.646806200Z"
    }
   },
   "id": "a365e3adcb35884e",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dutta_1 has been registered\n",
      "Dutta_10 has been registered\n",
      "Dutta_11 has been registered\n",
      "Dutta_12 has been registered\n",
      "Dutta_13 has been registered\n",
      "Dutta_2 has been registered\n",
      "Dutta_3 has been registered\n",
      "Dutta_4 has been registered\n",
      "Dutta_5 has been registered\n",
      "Dutta_6 has been registered\n",
      "Dutta_7 has been registered\n",
      "Dutta_8 has been registered\n",
      "Dutta_9 has been registered\n"
     ]
    }
   ],
   "source": [
    "embeddings_arcface = []\n",
    "embeddings_facenet  = []\n",
    "embeddings_vggface2 = []\n",
    "database_dir = \"Dutta\"\n",
    "for filename in os.listdir(database_dir):\n",
    "    if filename.lower().endswith(('.png','.jpg',',jpeg')):\n",
    "        label = os.path.splitext(filename)[0] # to extract the name of the filename\n",
    "        img_path = os.path.join(database_dir,filename)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        #Detect the faces \n",
    "        faces = RetinaFace.detect_faces(img)\n",
    "        if faces :\n",
    "            face = faces[next(iter(faces))]\n",
    "            x1,y1,x2,y2 = face['facial_area']\n",
    "            face_img = img[y1:y2, x1:x2]\n",
    "\n",
    "            #Extract the face embeddings from the image \n",
    "            arcface_embedding= DeepFace.represent(face_img, model_name='ArcFace', detector_backend=\"retinaface\",enforce_detection= False,align = True)[0]['embedding']\n",
    "            \n",
    "\n",
    "            # Convert embedding to float32 and ensure it's a 1D array\n",
    "            embedding = np.array(embedding).astype('float32').flatten()\n",
    "\n",
    "            arc_face_embeddings.append(embedding)\n",
    "            #label = np.array(label)\n",
    "            #labels.append(label)\n",
    "            print(f\"{label} has been registered\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T06:33:51.149053200Z",
     "start_time": "2024-12-11T06:29:56.029128100Z"
    }
   },
   "id": "4f50f874e8ff5fe0",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate the average value of the embeddings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "932c3589304df28c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspatial\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistance\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cosine\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mretinaface\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RetinaFace\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdeepface\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DeepFace\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from retinaface import RetinaFace\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Assuming you have the embeddings and labels stored for each model\n",
    "embeddings_arcface = np.array(embeddings_arcface)\n",
    "embeddings_facenet = np.array(embeddings_facenet)\n",
    "embeddings_vggface2 = np.array(embeddings_vggface2)\n",
    "labels = np.array(labels)\n",
    "\n",
    "def predict_label(query_embedding, embeddings_list, labels, weights=None):\n",
    "    \"\"\"\n",
    "    Predict the label of a given query embedding using an ensemble of face recognition models.\n",
    "    \n",
    "    Args:\n",
    "        query_embedding (np.ndarray): The embedding of the query face.\n",
    "        embeddings_list (list): A list of embedding arrays, one for each face recognition model.\n",
    "        labels (np.ndarray): The labels corresponding to the known faces.\n",
    "        weights (list, optional): A list of weights for each model. If not provided, equal weights are used.\n",
    "        \n",
    "    Returns:\n",
    "        str: The predicted label for the query face.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = [1 / len(embeddings_list)] * len(embeddings_list)\n",
    "\n",
    "    distances = []\n",
    "    for embeddings in embeddings_list:\n",
    "        distances.append([cosine(query_embedding, emb) for emb in embeddings])\n",
    "\n",
    "    weighted_distances = np.average(np.array(distances), axis=0, weights=weights)\n",
    "    nearest_index = np.argmin(weighted_distances)\n",
    "    return labels[nearest_index]\n",
    "\n",
    "def predict_label_single(query_embedding, embeddings, labels):\n",
    "    \"\"\"\n",
    "    Predict the label of a given query embedding using distance-based matching.\n",
    "    \n",
    "    Args:\n",
    "        query_embedding (np.ndarray): The embedding of the query face.\n",
    "        embeddings (np.ndarray): The embeddings of the known faces.\n",
    "        labels (np.ndarray): The labels corresponding to the known faces.\n",
    "        \n",
    "    Returns:\n",
    "        str: The predicted label for the query face.\n",
    "    \"\"\"\n",
    "    distances = [cosine(query_embedding, emb) for emb in embeddings]\n",
    "    nearest_index = np.argmin(distances)\n",
    "    return labels[nearest_index]\n",
    "\n",
    "# Example usage\n",
    "query_image_path = \"path/to/query/image.jpg\"\n",
    "query_img = cv2.imread(query_image_path)\n",
    "query_faces = RetinaFace.detect_faces(query_img)\n",
    "\n",
    "if query_faces:\n",
    "    for _, face in query_faces.items():\n",
    "        x1, y1, x2, y2 = face['facial_area']\n",
    "        query_face_img = query_img[y1:y2, x1:x2]\n",
    "\n",
    "        query_embedding_arcface = DeepFace.represent(query_face_img, model_name='ArcFace', detector_backend=\"retinaface\", enforce_detection=False, align=True)[0]['embedding']\n",
    "        query_embedding_facenet = DeepFace.represent(query_face_img, model_name='Facenet', detector_backend=\"retinaface\", enforce_detection=False, align=True)[0]['embedding']\n",
    "        query_embedding_vggface2 = DeepFace.represent(query_face_img, model_name='VGGFace2', detector_backend=\"retinaface\", enforce_detection=False, align=True)[0]['embedding']\n",
    "\n",
    "        query_embeddings = [\n",
    "            np.array(query_embedding_arcface).astype('float32').flatten(),\n",
    "            np.array(query_embedding_facenet).astype('float32').flatten(),\n",
    "            np.array(query_embedding_vggface2).astype('float32').flatten()\n",
    "        ]\n",
    "\n",
    "        predicted_label = predict_label(query_embeddings, [embeddings_arcface, embeddings_facenet, embeddings_vggface2], labels, weights=[0.5, 0.3, 0.2])\n",
    "        print(f\"Predicted label: {predicted_label}\")\n",
    "\n",
    "        # You can also use the single model prediction approach\n",
    "        # predicted_label_single = predict_label_single(query_embedding_arcface, embeddings_arcface, labels)\n",
    "        # print(f\"Predicted label (single model): {predicted_label_single}\")\n",
    "else:\n",
    "    print(\"No faces detected in the query image.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T06:33:51.533944200Z",
     "start_time": "2024-12-11T06:33:51.191752500Z"
    }
   },
   "id": "33638f28fc783e11",
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
