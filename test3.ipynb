{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing the libraries "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c39623b8d8479d40"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-11T05:56:10.130295400Z",
     "start_time": "2024-12-11T05:55:54.478151800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Jet Brains\\DataSpell\\Attendance using facial rec\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "from retinaface import RetinaFace\n",
    "from deepface import DeepFace\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import datetime as datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import faiss\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "# Paths\n",
    "DATABASE_DIR = 'path_to_database_images'\n",
    "EMBEDDINGS_FILE = 'embeddings.pkl'\n",
    "ATTENDANCE_FILE = 'attendance_log.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T05:56:10.498147100Z",
     "start_time": "2024-12-11T05:56:10.129225700Z"
    }
   },
   "id": "7e7a877d553ca529",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded from embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "DATABASE_DIR = 'students'\n",
    "# Check if embeddings.pkl exists\n",
    "if os.path.exists(EMBEDDINGS_FILE):\n",
    "    # Load existing embeddings and labels\n",
    "    with open(EMBEDDINGS_FILE, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    embeddings = data['embeddings']\n",
    "    labels = data['labels']\n",
    "    print(\"Embeddings loaded from embeddings.pkl\")\n",
    "else: \n",
    "    for filename in os.listdir(DATABASE_DIR):\n",
    "        if filename.lower().endswith(('.png','.jpg',',jpeg')):\n",
    "            label = os.path.splitext(filename)[0] # to extract the name of the filename\n",
    "            img_path = os.path.join(DATABASE_DIR,filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            #Detect the faces \n",
    "            faces = RetinaFace.detect_faces(img)\n",
    "            if faces :\n",
    "                face = faces[next(iter(faces))]\n",
    "                x1,y1,x2,y2 = face['facial_area']\n",
    "                face_img = img[y1:y2, x1:x2]\n",
    "                \n",
    "                #Extract the face embeddings from the image \n",
    "                embedding_original = DeepFace.represent(face_img, model_name='ArcFace', detector_backend=\"retinaface\",enforce_detection= False,align = True)\n",
    "                embedding_dict = embedding_original[0]\n",
    "                embedding = embedding_dict[\"embedding\"]\n",
    "    \n",
    "                # Convert embedding to float32 and ensure it's a 1D array\n",
    "                embedding = np.array(embedding).astype('float32').flatten()\n",
    "    \n",
    "                embeddings.append(embedding)\n",
    "                label = np.array(label)\n",
    "                labels.append(label)\n",
    "                print(f\"{label} has been registered\")\n",
    "            else:\n",
    "                print(f'No face detected in the {filename}')        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T05:56:10.507290200Z",
     "start_time": "2024-12-11T05:56:10.502456100Z"
    }
   },
   "id": "187c04f0c72cf587",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings computed and stored in embeddings.pkl.\n"
     ]
    }
   ],
   "source": [
    "with open(EMBEDDINGS_FILE, 'wb') as f:\n",
    "    pickle.dump({'embeddings': embeddings, 'labels': labels}, f)\n",
    "print(\"Embeddings computed and stored in embeddings.pkl.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T05:56:10.519651600Z",
     "start_time": "2024-12-11T05:56:10.511077400Z"
    }
   },
   "id": "637c84c8dea55126",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings computed and stored.\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(labels)\n",
    "with open(EMBEDDINGS_FILE, 'wb') as f:\n",
    "    pickle.dump({'embeddings': embeddings, 'labels': labels}, f)\n",
    "print(\"Embeddings computed and stored.\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T05:56:10.531086700Z",
     "start_time": "2024-12-11T05:56:10.520649800Z"
    }
   },
   "id": "10ccaa8a412d82fd",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings indexed: 20\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings and labels\n",
    "with open('embeddings.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "database_embeddings = data['embeddings']  # Shape: (num_samples, embedding_dim)\n",
    "database_labels = data['labels']\n",
    "database_embeddings = np.vstack(database_embeddings)\n",
    "# Dimension of the embeddings (e.g., 512 for Facenet)\n",
    "dimension = database_embeddings.shape[1]\n",
    "\n",
    "# Initialize FAISS index (Flat index for exact search)\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(database_embeddings)\n",
    "\n",
    "print(f\"Total embeddings indexed: {index.ntotal}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T05:56:10.631637400Z",
     "start_time": "2024-12-11T05:56:10.529082700Z"
    }
   },
   "id": "546733fc044d4e26",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae42f019ad4fa0f6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.373809]]\n",
      "['Sahil Burnawal']\n",
      "[[17.361927]]\n",
      "[[12.261818]]\n",
      "['Harish Gownatham']\n",
      "[[15.32501]]\n",
      "[[11.620643]]\n",
      "['Haider Rizvy']\n",
      "[[17.566427]]\n",
      "[[15.540199]]\n",
      "[[18.341595]]\n",
      "[[16.411451]]\n",
      "[[9.134539]]\n",
      "['Ayon Binayak Ghosh']\n",
      "[[12.400358]]\n",
      "['Divya Raj ']\n",
      "[[11.919134]]\n",
      "['Shaurya']\n",
      "[[13.009733]]\n",
      "['Aman']\n"
     ]
    }
   ],
   "source": [
    " classroom_image = cv2.imread('classroom3.jpg')\n",
    "faces = RetinaFace.detect_faces(img_path = \"classroom3.jpg\")\n",
    "threshold = 40\n",
    "for face_key in faces:\n",
    "    face = faces[face_key]\n",
    "    x1,y1,x2,y2 = face['facial_area']\n",
    "    individual_image = classroom_image[y1:y2, x1:x2]\n",
    "    individual_embedding = DeepFace.represent(img_path = individual_image , model_name='ArcFace', detector_backend=\"retinaface\",enforce_detection= False,align = True)[0]\n",
    "    individual_embedding = individual_embedding['embedding']\n",
    "    individual_embedding = np.array(individual_embedding).astype('float32').reshape(1,-1)\n",
    "    distance , indices = index.search(individual_embedding, k=1)\n",
    "    print(distance)\n",
    "    ##print(indices)\n",
    "    threshold = 15\n",
    "    if distance < threshold:\n",
    "        print(database_labels[indices[0]])\n",
    "        cv2.rectangle(classroom_image,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "        cv2.putText(classroom_image,str(database_labels[indices[0]]),(x1-10,y1-10),3,1.5,(255,0,0),1,cv2.LINE_AA)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T05:58:29.229445700Z",
     "start_time": "2024-12-11T05:56:10.542232100Z"
    }
   },
   "id": "b9f2bf7977530a91",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"output.jpg\", classroom_image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T05:58:29.474416600Z",
     "start_time": "2024-12-11T05:58:29.224389100Z"
    }
   },
   "id": "dae6c7b7ae6a5b60",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.385036]]\n",
      "[[4]]\n",
      "['Aniket ']\n",
      "[[11.351365]]\n",
      "[[12]]\n",
      "['Harsh Murmu']\n",
      "[[16.218374]]\n",
      "[[6]]\n",
      "['Ankit']\n"
     ]
    }
   ],
   "source": [
    "  classroom_image = cv2.imread('classroom2.jpg')\n",
    "faces = RetinaFace.detect_faces(img_path = \"classroom2.jpg\")\n",
    "threshold = 40\n",
    "for face_key in faces:\n",
    "    face = faces[face_key]\n",
    "    x1,y1,x2,y2 = face['facial_area']\n",
    "    individual_image = classroom_image[y1:y2, x1:x2]\n",
    "    individual_embedding = DeepFace.represent(img_path = individual_image , model_name='ArcFace', detector_backend=\"retinaface\",enforce_detection= False,align = True)[0]\n",
    "    individual_embedding = individual_embedding['embedding']\n",
    "    individual_embedding = np.array(individual_embedding).astype('float32').reshape(1,-1)\n",
    "    distance , indices = index.search(individual_embedding, k=1)\n",
    "    print(distance)\n",
    "    print(indices)\n",
    "    print(database_labels[indices[0]])\n",
    "    cv2.rectangle(classroom_image,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "    cv2.putText(classroom_image,str(database_labels[indices[0]]),(x1-10,y1-10),3,1.5,(255,0,0),1,cv2.LINE_AA)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T05:59:01.945284200Z",
     "start_time": "2024-12-11T05:58:29.477970300Z"
    }
   },
   "id": "a56f334f5b692948",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"Output2.jpg\",classroom_image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T05:59:02.004278300Z",
     "start_time": "2024-12-11T05:59:01.952283100Z"
    }
   },
   "id": "9dbc14e784c628d7",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.373809]]\n",
      "['Sahil Burnawal']\n",
      "[[17.361927]]\n",
      "['Aniket ']\n",
      "[[12.261818]]\n",
      "['Harish Gownatham']\n",
      "[[15.32501]]\n",
      "['Anish']\n",
      "[[11.620643]]\n",
      "['Haider Rizvy']\n",
      "[[17.566427]]\n",
      "['Harish Gownatham']\n",
      "[[15.540199]]\n",
      "['Ayon Binayak Ghosh']\n",
      "[[18.341595]]\n",
      "['Krishnendu Basak']\n",
      "[[16.411451]]\n",
      "['Basharat']\n",
      "[[8.421034]]\n",
      "['Ayon Binayak Ghosh']\n",
      "[[12.400358]]\n",
      "['Divya Raj ']\n",
      "[[11.919134]]\n",
      "['Shaurya']\n",
      "[[13.009733]]\n",
      "['Aman']\n"
     ]
    }
   ],
   "source": [
    " classroom_image = cv2.imread('classroom3.jpg')\n",
    "faces = RetinaFace.detect_faces(img_path = \"classroom3.jpg\")\n",
    "threshold = 40\n",
    "for face_key in faces:\n",
    "    face = faces[face_key]\n",
    "    x1,y1,x2,y2 = face['facial_area']\n",
    "    individual_image = classroom_image[y1:y2, x1:x2]\n",
    "    individual_embedding = DeepFace.represent(img_path = individual_image , model_name='ArcFace', detector_backend=\"retinaface\",enforce_detection= False,align = True)[0]\n",
    "    individual_embedding = individual_embedding['embedding']\n",
    "    individual_embedding = np.array(individual_embedding).astype('float32').reshape(1,-1)\n",
    "    distance , indices = index.search(individual_embedding, k=1)\n",
    "    print(distance)\n",
    "    ##print(indices)\n",
    "    threshold = 20\n",
    "    if distance < threshold:\n",
    "        print(database_labels[indices[0]])\n",
    "        cv2.rectangle(classroom_image,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "        cv2.putText(classroom_image,str(database_labels[indices[0]]),(x1-10,y1-10),3,1.5,(255,0,0),1,cv2.LINE_AA)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T06:06:07.787315400Z",
     "start_time": "2024-12-11T06:04:27.458370600Z"
    }
   },
   "id": "7155efbba1934042",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"output3.jpg\", classroom_image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T06:06:08.005705200Z",
     "start_time": "2024-12-11T06:06:07.789584800Z"
    }
   },
   "id": "ded99f1580a04da1",
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
