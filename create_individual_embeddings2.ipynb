{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "from deepface import DeepFace\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "class FaceRecognitionSystem:\n",
    "    def __init__(self, database_dir):\n",
    "        \"\"\"\n",
    "        Initialize the face recognition system with a database of known faces\n",
    "        \n",
    "        Args:\n",
    "            database_dir (str): Directory containing images of known individuals\n",
    "        \"\"\"\n",
    "        self.database_dir = database_dir\n",
    "\n",
    "        # Dictionaries to store embeddings and labels for different models\n",
    "        self.embeddings = {\n",
    "            'ArcFace': {'embeddings': [], 'labels': []},\n",
    "            'Facenet': {'embeddings': [], 'labels': []},\n",
    "            'VGGFace2': {'embeddings': [], 'labels': []}\n",
    "        }\n",
    "\n",
    "        # Load known faces\n",
    "        self.load_database()\n",
    "\n",
    "    def load_database(self):\n",
    "        \"\"\"\n",
    "        Load face embeddings from images in the database directory\n",
    "        \"\"\"\n",
    "        for filename in os.listdir(self.database_dir):\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                # Extract label from filename (assuming filename is the person's name)\n",
    "                label = os.path.splitext(filename)[0]\n",
    "                img_path = os.path.join(self.database_dir, filename)\n",
    "\n",
    "                try:\n",
    "                    # Read the image\n",
    "                    img = cv2.imread(img_path)\n",
    "\n",
    "                    # Detect faces\n",
    "                    faces = RetinaFace.detect_faces(img)\n",
    "\n",
    "                    if faces:\n",
    "                        # Get the first detected face\n",
    "                        face = faces[next(iter(faces))]\n",
    "                        x1, y1, x2, y2 = face['facial_area']\n",
    "                        face_img = img[y1:y2, x1:x2]\n",
    "\n",
    "                        # Extract embeddings using different models\n",
    "                        for model in ['ArcFace', 'Facenet', 'VGGFace2']:\n",
    "                            embedding = self.extract_embedding(face_img, model)\n",
    "\n",
    "                            if embedding is not None:\n",
    "                                self.embeddings[model]['embeddings'].append(embedding)\n",
    "                                self.embeddings[model]['labels'].append(label)\n",
    "\n",
    "                        print(f\"{label} has been registered\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "    def extract_embedding(self, face_img, model_name):\n",
    "        \"\"\"\n",
    "        Extract face embedding using specified model\n",
    "        \n",
    "        Args:\n",
    "            face_img (np.ndarray): Cropped face image\n",
    "            model_name (str): Name of the face recognition model\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Face embedding\n",
    "        \"\"\"\n",
    "        try:\n",
    "            embedding = DeepFace.represent(\n",
    "                face_img,\n",
    "                model_name=model_name,\n",
    "                detector_backend=\"retinaface\",\n",
    "                enforce_detection=False,\n",
    "                align=True\n",
    "            )[0]['embedding']\n",
    "\n",
    "            return np.array(embedding).astype('float32').flatten()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting {model_name} embedding: {e}\")\n",
    "            return None\n",
    "\n",
    "    def predict_identity(self, query_face_img, threshold=0.5, weights=None):\n",
    "        \"\"\"\n",
    "        Predict the identity of a query face using multiple models\n",
    "        \n",
    "        Args:\n",
    "            query_face_img (np.ndarray): Cropped query face image\n",
    "            threshold (float): Maximum distance for a match\n",
    "            weights (dict): Weights for different models\n",
    "        \n",
    "        Returns:\n",
    "            str: Predicted identity or 'Unknown'\n",
    "        \"\"\"\n",
    "        # Default weights if not provided\n",
    "        if weights is None:\n",
    "            weights = {\n",
    "                'ArcFace': 0.5,\n",
    "                'Facenet': 0.3,\n",
    "                'VGGFace2': 0.2\n",
    "            }\n",
    "\n",
    "        # Extract embeddings for the query face\n",
    "        query_embeddings = {}\n",
    "        for model in ['ArcFace', 'Facenet', 'VGGFace2']:\n",
    "            embedding = self.extract_embedding(query_face_img, model)\n",
    "            if embedding is not None:\n",
    "                query_embeddings[model] = embedding\n",
    "\n",
    "        # Aggregate predictions from different models\n",
    "        predictions = {}\n",
    "        for model, query_embedding in query_embeddings.items():\n",
    "            # Calculate cosine distances\n",
    "            distances = [cosine(query_embedding, emb) for emb in self.embeddings[model]['embeddings']]\n",
    "\n",
    "            if distances:\n",
    "                # Find the nearest neighbor\n",
    "                nearest_index = np.argmin(distances)\n",
    "                nearest_distance = distances[nearest_index]\n",
    "\n",
    "                # Check if the distance is within the threshold\n",
    "                if nearest_distance <= threshold:\n",
    "                    label = self.embeddings[model]['labels'][nearest_index]\n",
    "                    predictions[label] = predictions.get(label, 0) + weights.get(model, 0)\n",
    "\n",
    "        # Return the most confident prediction\n",
    "        if predictions:\n",
    "            return max(predictions, key=predictions.get)\n",
    "\n",
    "        return 'Unknown'\n",
    "\n",
    "    def recognize_faces(self, image_path):\n",
    "        \"\"\"\n",
    "        Recognize faces in a given image\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the input image\n",
    "        \n",
    "        Returns:\n",
    "            list: List of recognized identities\n",
    "        \"\"\"\n",
    "        # Read the image\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        # Detect faces\n",
    "        faces = RetinaFace.detect_faces(img)\n",
    "\n",
    "        recognized_faces = []\n",
    "\n",
    "        if faces:\n",
    "            for _, face in faces.items():\n",
    "                x1, y1, x2, y2 = face['facial_area']\n",
    "                face_img = img[y1:y2, x1:x2]\n",
    "\n",
    "                # Predict identity\n",
    "                identity = self.predict_identity(face_img)\n",
    "                recognized_faces.append(identity)\n",
    "\n",
    "                # Optional: Draw bounding box and identity on the image\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(img, identity, (x1, y1-10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            # Optional: Display the image with recognized faces\n",
    "            cv2.imshow('Face Recognition', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        return recognized_faces\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the face recognition system with a database directory\n",
    "    face_system = FaceRecognitionSystem(\"path/to/your/database/directory\")\n",
    "\n",
    "    # Recognize faces in a query image\n",
    "    recognized_faces = face_system.recognize_faces(\"path/to/query/image.jpg\")\n",
    "    print(\"Recognized Faces:\", recognized_faces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
